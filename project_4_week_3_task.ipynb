{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfHPDMiXT0Py"
      },
      "source": [
        "# **Feature Extraction and Price Prediction for Mobile Phones**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tApHfjAhN4Br"
      },
      "source": [
        "**Problem Statement**\n",
        "- I worked for a prominent organization that specializes in selling mobile phones. The organization is keen to enhance its pricing strategy by gaining a deeper understanding of the key features that influence the prices of mobile phones in today's highly competitive market. my objective is to build a predictive model that can accurately estimate the price of a mobile phone based on its features. To achieve this, you'll perform a feature extraction analysis to identify the most influential features.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dEsA1HAFUO2v"
      },
      "source": [
        "**Project Description:**\n",
        "- In this project, I worked with a dataset that contains detailed information about various mobile phones, including their model, color, memory, RAM, battery capacity, rear camera specifications, front camera specifications, presence of AI lens, mobile height, processor, and, most importantly, the price.\n",
        "- My goal is to develop a predictive model for mobile phone prices.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BLjlZ5GsRS8v"
      },
      "source": [
        "**Data Wrangling**\n",
        "- It convert and format raw data to usable format down to data science pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ge-SQN-2Svt8"
      },
      "source": [
        "# **Data Exploration:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6Tq744AUwv2"
      },
      "source": [
        "**Import Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "BWS2z96JN3Id"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "# For Jupyter Notebook\n",
        "%matplotlib inline\n",
        "warnings.filterwarnings('ignore')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MStZMXYhTLJG"
      },
      "source": [
        "**Loading the given Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "MeDXdqJdOZ1t",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "outputId": "9523cda3-8188-440b-af3d-01e63d9c394c"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/Processed_Flipdata - Processed_Flipdata (1).csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-86e5a93a231c>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/Processed_Flipdata - Processed_Flipdata (1).csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    910\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 912\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 577\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1659\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1660\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1661\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1662\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1663\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    857\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/Processed_Flipdata - Processed_Flipdata (1).csv'"
          ]
        }
      ],
      "source": [
        "data=pd.read_csv('/content/Processed_Flipdata - Processed_Flipdata (1).csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "opxGDrYeO4q4"
      },
      "outputs": [],
      "source": [
        "data # to check data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m-xJdAtaU9zw"
      },
      "source": [
        "**Check the shape of data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EI8_tUuURuE3"
      },
      "outputs": [],
      "source": [
        "data.shape[0]#only no of rows"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['Prize'].unique()\n"
      ],
      "metadata": {
        "id": "SmW49vfJ4k_7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9odRMo84Rxrj"
      },
      "outputs": [],
      "source": [
        "data.shape[1]#only no of columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IjWDj7-7VDdh"
      },
      "source": [
        "**Check first five Rows**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ofg7w-oNPAqy"
      },
      "outputs": [],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ou0WaG9lVNFD"
      },
      "source": [
        "**Check all the column names of dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nzdi4aEjPF1S"
      },
      "outputs": [],
      "source": [
        "data.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gbkr89s1DBtQ"
      },
      "outputs": [],
      "source": [
        "# Number of uniqe elements in each columns\n",
        "unique = data.nunique()\n",
        "unique.to_frame().T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M2XF9zh6C_UC"
      },
      "outputs": [],
      "source": [
        "data.rename(columns={'Prize': 'Price'}, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Convert the Price column to numeric:**"
      ],
      "metadata": {
        "id": "Df6_GTsTvhsK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove non-numeric characters if necessary\n",
        "data['Price'] = data['Price'].replace('[\\$,]', '', regex=True).astype(float)\n",
        "\n",
        "# Verify the conversion\n",
        "data['Price'].head()\n"
      ],
      "metadata": {
        "id": "EJu8VvLNvfmA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.dtypes"
      ],
      "metadata": {
        "id": "6cksRQ-Kv2Ua"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "id": "RiSGMkv3s8qY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qfS_vkNnVX0P"
      },
      "source": [
        "**check info of dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MNV7gXxMPJwF"
      },
      "outputs": [],
      "source": [
        "# Getting the informaatin of the data\n",
        "data.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "blKE3KGdWfoY"
      },
      "source": [
        "**Descriptive Statistics**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHByjnMXWYmw"
      },
      "source": [
        "**Summary Statistics**\n",
        "- **Measure of central Tendancy**\n",
        "- **Mean**: Mean is the average of all values\n",
        "- **mode**: Median is the middle value when data is sorted.\n",
        "-**Median** : Mode is the most frequently occurring value in the dataset.\n",
        "-**Describe()** is used to view some basic statistical details like percentile, mean, std, etc. of a data frame or a series of numeric values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WfHrkN38PPmj"
      },
      "outputs": [],
      "source": [
        "data.describe(include='all')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0PtYuZ1HPjeg"
      },
      "outputs": [],
      "source": [
        "data.dtypes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QD3J2yFNVwZY"
      },
      "source": [
        "**It filters columns that have object data types, which typically represent strings or categorical variables.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4RTduzESPtlL"
      },
      "outputs": [],
      "source": [
        "cat_col=data.select_dtypes(include='object')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l2ciHJ6XQBvY"
      },
      "outputs": [],
      "source": [
        "cat_col"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s4X29sZZV2P7"
      },
      "source": [
        "**It filters columns that have int64,float data types, which typically represent numerical features**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JWtpBbCDQ6OI"
      },
      "outputs": [],
      "source": [
        "num_col=data.select_dtypes(include=['int64', 'float'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_col"
      ],
      "metadata": {
        "id": "Gy0fnCG3xyRC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rn6cL9j8WqsM"
      },
      "source": [
        "-**Measure of dispersion**: Measures of Dispersion are used to represent the scattering of data. These are the numbers that show the various aspects of the data spread across various parameters.\n",
        " - **Range**: It is defined as the difference between the largest and the smallest value in the distribution.\n",
        " -**Starndard deviation**: It is the square root of the arithmetic average of the square of the deviations measured from the mean.\n",
        " -**percentiles**:  How many of the values are less than the given percentile\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "joGgB_E_Y4Vg"
      },
      "outputs": [],
      "source": [
        "data['Price'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8tpPEm6AZgYv"
      },
      "outputs": [],
      "source": [
        "data['Price'].nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Psw9R-gnZB3a"
      },
      "outputs": [],
      "source": [
        "data['Price'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r4KQB3DGgyMi"
      },
      "outputs": [],
      "source": [
        "numerical_summary = num_col.describe().transpose()\n",
        "palette = sns.color_palette(\"viridis\", as_cmap=True)\n",
        "numerical_summary.style.background_gradient(cmap=palette)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The dataset comprises 541 observations, detailing various attributes like memory, RAM, battery capacity, AI lens presence, and mobile height. Key highlights include a median memory of 128.000000, a median RAM of 6.000000, and a median battery capacity of 5000.000000 mAh.**"
      ],
      "metadata": {
        "id": "AHUn_oxCq7eK"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FgS0UapDknkv"
      },
      "source": [
        "### **The range of values for each feature.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ni_ZHhOihPQ_"
      },
      "outputs": [],
      "source": [
        "# Check range for 'Memory'\n",
        "if data['Memory'].dtype in ['int64', 'float64']:\n",
        "    print(f\"Memory: min = {data['Memory'].min()}, max = {data['Memory'].max()}\")\n",
        "else:\n",
        "    print(f\"Memory: unique values = {data['Memory'].unique()}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check range for 'Price'\n",
        "if data['Price'].dtype in ['int64', 'float64']:\n",
        "    print(f\"Price: min = {data['Price'].min()}, max = {data['Price'].max()}\")\n",
        "else:\n",
        "    print(f\"Price: unique values = {data['Price'].unique()}\")"
      ],
      "metadata": {
        "id": "oOixzwqZwtLi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "30I8JTiahPSa"
      },
      "outputs": [],
      "source": [
        " #Check range for 'RAM'\n",
        "if data['RAM'].dtype in ['int64', 'float64']:\n",
        "    print(f\"RAM: min = {data['RAM'].min()}, max = {data['RAM'].max()}\")\n",
        "else:\n",
        "    print(f\"RAM: unique values = {data['RAM'].unique()}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7864dvXnhPTc"
      },
      "outputs": [],
      "source": [
        "# Check range for 'Battery_'\n",
        "if data['Battery_'].dtype in ['int64', 'float64']:\n",
        "    print(f\"Battery_: min = {data['Battery_'].min()}, max = {data['Battery_'].max()}\")\n",
        "else:\n",
        "    print(f\"Battery_: unique values = {data['Battery_'].unique()}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VRODQMwljYqC"
      },
      "outputs": [],
      "source": [
        "# Check range for 'AI Lens'\n",
        "if data['AI Lens'].dtype in ['int64', 'float64']:\n",
        "    print(f\"AI Lens: min = {data['AI Lens'].min()}, max = {data['AI Lens'].max()}\")\n",
        "else:\n",
        "    print(f\"AI Lens: unique values = {data['AI Lens'].unique()}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mLR1pHs1jdkA"
      },
      "outputs": [],
      "source": [
        "# Check range for 'Mobile Height'\n",
        "if data['Mobile Height'].dtype in ['int64', 'float64']:\n",
        "    print(f\"Mobile Height: min = {data['Mobile Height'].min()}, max = {data['Mobile Height'].max()}\")\n",
        "else:\n",
        "    print(f\"Mobile Height: unique values = {data['Mobile Height'].unique()}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NhOJF5bXjhUc"
      },
      "outputs": [],
      "source": [
        "# Check range for 'Model'\n",
        "print(f\"Model: unique values = {data['Model'].unique()}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lQ-wqr1MjmPw"
      },
      "outputs": [],
      "source": [
        "# Check range for 'Colour'\n",
        "print(f\"Colour: unique values = {data['Colour'].unique()}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F6rMpzMVj2ez"
      },
      "outputs": [],
      "source": [
        "# Check range for 'Rear Camera'\n",
        "print(f\"Rear Camera: unique values = {data['Rear Camera'].unique()}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gQAMdVhgj4x8"
      },
      "outputs": [],
      "source": [
        "# Check range for 'Front Camera'\n",
        "print(f\"Front Camera: unique values = {data['Front Camera'].unique()}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nzz2ToSHj7WA"
      },
      "outputs": [],
      "source": [
        "# Check range for 'Processor_'\n",
        "print(f\"Processor_: unique values = {data['Processor_'].unique()}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qbZAX4tj_UD1"
      },
      "source": [
        "# **Data Visualization**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O3jQo5E0Xeac"
      },
      "source": [
        "## **Line Chart:**\n",
        "Line graphs are used to track changes over short and long periods of time. When smaller changes exist, line graphs are better to use than bar graphs. Line graphs can also be used to compare changes over the same period of time for more than one group"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WqU44U_NXo2W"
      },
      "outputs": [],
      "source": [
        "#Plot the Data\n",
        "plt.figure(figsize=(16,6))\n",
        "sns.lineplot(data=data)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3TfNJjehrNG0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zcH7ynj2YpUv"
      },
      "outputs": [],
      "source": [
        "#We will begin by printing the names of all columns\n",
        "list(data.columns)\n",
        "#We plot the lines corresponding to the first two columns in the dataset.\n",
        "plt.figure(figsize=(14,6))\n",
        "plt.title(\"Battery power by products\")\n",
        "#Line chart shows battery power for the each products\n",
        "sns.lineplot(data=data['Battery_'], label=\"Battery Size\")\n",
        "#Line chart shows best price for the each powers\n",
        "sns.lineplot(data=data['Price'], label= \"Best price\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KL64BpoXZWgi"
      },
      "source": [
        "## **Bar Chart**\n",
        "- Bar graphs are used to compare things between different groups or to track changes over time. However, when trying to measure change over time, bar graphs are best when the changes are larger."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5WWdgUqRZpdH"
      },
      "outputs": [],
      "source": [
        "#Set the width and height of the figure\n",
        "plt.figure(figsize=(10,6))\n",
        "#Add title\n",
        "plt.title(\"Average battery power by phone model\")\n",
        "#Bar chart showing average battery power by phone brands\n",
        "# Group the data by 'Model' and calculate the mean battery power for each group.\n",
        "# Then reset the index to convert the result into a DataFrame suitable for plotting.\n",
        "model_battery = data.groupby('Model')['Battery_'].mean().reset_index()\n",
        "sns.barplot(x='Model', y='Battery_', data=model_battery)\n",
        "#Add label for vertical axis\n",
        "plt.ylabel(\"battery_size \")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.express as px\n",
        "fig = px.violin(data, x=\"Price\", y=\"RAM\", color=\"Price\", box=True,points = \"all\")\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "bMEp425bNrZ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = px.scatter_3d(data, x='RAM', y='Memory', z='Price',\n",
        "              color='Price')\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "hjKXAHi_QLm2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Histogram**"
      ],
      "metadata": {
        "id": "Op5yGiI-qPEN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vK04IFyyp-od"
      },
      "outputs": [],
      "source": [
        "# Visualize data using histograms\n",
        "for column in num_col:\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.hist(data[column], bins=20, edgecolor='k', alpha=0.7)\n",
        "    plt.title(f'Histogram for {column}')\n",
        "    plt.xlabel(column)\n",
        "    plt.ylabel('Frequency')\n",
        "    plt.grid(True)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Box Plot**"
      ],
      "metadata": {
        "id": "08Hctr_oqX7O"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JWyV_qGt_iyu"
      },
      "outputs": [],
      "source": [
        "#  Create the plot grid\n",
        "rows = 3\n",
        "columns = 2\n",
        "\n",
        "fig, axes = plt.subplots(rows,columns, figsize=(30,30))\n",
        "\n",
        "x, y = 0, 0\n",
        "\n",
        "for i, column in enumerate(num_col):\n",
        "    sns.boxplot(x=data[column], ax=axes[x, y])\n",
        "\n",
        "    if y < columns-1:\n",
        "        y += 1\n",
        "    else: # Simplified condition - reset y when a row is filled\n",
        "        x += 1\n",
        "        y = 0\n",
        "\n",
        "    # Check if we've filled all subplots\n",
        "    if x >= rows:\n",
        "        break\n",
        "\n",
        "plt.tight_layout() # Adjust layout to prevent overlapping\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n6-sO22NUipg"
      },
      "outputs": [],
      "source": [
        "#Check noises by pairplot\n",
        "sns.set_palette('crest')\n",
        "sns.set_style('darkgrid')\n",
        "# Convert num_cols to a list\n",
        "dnp = sns.pairplot(data, vars=num_col.columns.tolist())\n",
        "\n",
        "# Add axis labels and tick labels to the plot\n",
        "dnp.set(xticklabels=[], yticklabels=[])\n",
        "dnp.axes[0][0].set_ylabel(num_col.columns.tolist()[0], fontsize=14)\n",
        "dnp.axes[-1][0].set_xlabel(num_col.columns.tolist()[0], fontsize=14)\n",
        "dnp.axes[-1][0].xaxis.labelpad = 20\n",
        "dnp.axes[-1][-1].yaxis.labelpad = 20\n",
        "\n",
        "# Title of the plot\n",
        "dnp.fig.suptitle('Pairplot for each variable\\n(Range: min={}, max={})'.format(data[num_col.columns].min().min(), data[num_col.columns].max().max()), y=1.03, fontsize=25)\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sp90SNnrlkE2"
      },
      "source": [
        "# **Data Cleaning:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_Vr3KYhlsWj"
      },
      "source": [
        "**Missing Values**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hjsgd3rWlU5_"
      },
      "outputs": [],
      "source": [
        "data.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing values\n",
        "plt.figure(figsize=(22,4))\n",
        "sns.heatmap((data.isna().sum()).to_frame(name='').T,cmap='GnBu', annot=True,\n",
        "             fmt='0.0f').set_title('Count missing values', fontsize=18)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ZBfOMu5R_taH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i_U5On6qLKsl"
      },
      "outputs": [],
      "source": [
        "# Check for duplicates\n",
        "data.duplicated().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "glMPUqQ_LSIh"
      },
      "outputs": [],
      "source": [
        "# Remove duplicates in-place\n",
        "data.drop_duplicates(inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.columns"
      ],
      "metadata": {
        "id": "4TFNzSJA0Qg0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IgIvJtSCEB6O"
      },
      "outputs": [],
      "source": [
        "# Check for remaining missing values\n",
        "missing_values = data.isnull().sum()\n",
        "print(missing_values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JoCBPddOi0cW"
      },
      "outputs": [],
      "source": [
        "data.duplicated().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "igWeR6fMEF38"
      },
      "outputs": [],
      "source": [
        "# Drop the \"Unnamed: 0\" column\n",
        "data = data.drop(columns=['Unnamed: 0'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_cols = data.select_dtypes(include=['int64', 'float64'])"
      ],
      "metadata": {
        "id": "3AU1QWaRipE9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pJyjZWVNmcX5"
      },
      "source": [
        "## **Detect Outliers**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the IQR for each column in the dataset\n",
        "Q1 = num_cols.quantile(0.25)\n",
        "Q3 = num_cols.quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "\n",
        "# Identify outliers using the IQR method\n",
        "outliers = ((num_cols < (Q1 - 1.5 * IQR)) | (num_cols > (Q3 + 1.5 * IQR)))\n",
        "\n",
        "# Count the number of outliers for each variable\n",
        "num_outliers = outliers.sum()\n",
        "\n",
        "# Number of outliers for each variable\n",
        "num_outliers.to_frame().T"
      ],
      "metadata": {
        "id": "9fm8GOAmEPbR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Remove Outliers**"
      ],
      "metadata": {
        "id": "6cQL5KhIEfus"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_data(df):\n",
        "    removed_outliers_info = {}  # Dictionary to store information about removed outliers\n",
        "\n",
        "    def remove_outliers(column):\n",
        "        Q1 = column.quantile(0.25)\n",
        "        Q3 = column.quantile(0.75)\n",
        "        IQR = Q3 - Q1\n",
        "        return column[(column >= Q1 - 1.5 * IQR) & (column <= Q3 + 1.5 * IQR)]\n",
        "\n",
        "    # Iterate over each numerical column\n",
        "    for column in df.select_dtypes(include=['float64', 'int64']).columns:\n",
        "        # Count rows before outlier removal\n",
        "        rows_before = df.shape[0]\n",
        "\n",
        "        # Remove outliers from the column\n",
        "        cleaned_column = remove_outliers(df[column])\n",
        "\n",
        "        # Count rows after outlier removal\n",
        "        rows_after = cleaned_column.shape[0]\n",
        "\n",
        "        # Calculate number of outliers removed\n",
        "        outliers_removed = rows_before - rows_after\n",
        "\n",
        "        # Store information about removed outliers\n",
        "        removed_outliers_info[column] = outliers_removed\n",
        "\n",
        "        # Replace the column with cleaned data and fill NaNs with median\n",
        "        df[column] = cleaned_column\n",
        "        df[column].fillna(cleaned_column.median(), inplace=True)\n",
        "\n",
        "    # Drop rows with any remaining NaN values\n",
        "    df.dropna(inplace=True)\n",
        "\n",
        "    # Create a DataFrame of cleaned data\n",
        "    cleaned_data = df.copy()\n",
        "\n",
        "    # Return cleaned DataFrame and removed outliers information\n",
        "    return cleaned_data, pd.DataFrame.from_dict(removed_outliers_info, orient='index', columns=['Outliers Removed']).T\n",
        "\n",
        "# Call the function to clean data\n",
        "cleaned_data, df_removed_outliers = clean_data(data)\n",
        "\n",
        "print(\"\\nInformation about removed outliers:\")\n",
        "df_removed_outliers"
      ],
      "metadata": {
        "id": "PxaNyz9SjJR6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_data"
      ],
      "metadata": {
        "id": "1ndaA1yDjbmh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.isnull().sum()"
      ],
      "metadata": {
        "id": "iTbC3a52oKyM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['Price'].isnull().sum()"
      ],
      "metadata": {
        "id": "qSGofkP58NlX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Exploratory Data Analysis**"
      ],
      "metadata": {
        "id": "pslFIhCk0bep"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**What are the most popular Model?**"
      ],
      "metadata": {
        "id": "t2wRbHPbX5FV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "brand_counts = data['Model'].value_counts()\n",
        "\n",
        "# Get the top 5 most popular models\n",
        "top_models = brand_counts.head(5)\n",
        "\n",
        "# Create a bar chart using Plotly Express\n",
        "fig = px.bar(x=top_models.index, y=top_models.values,\n",
        "             labels={'x': 'Model', 'y': 'Count'},\n",
        "             title='Top 5 Most Popular Models',\n",
        "             template='plotly_dark')\n",
        "\n",
        "# Update layout for better readability\n",
        "fig.update_layout(xaxis_tickangle=-45, xaxis_tickfont_size=12)\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "_LkJdvtJxsOO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Whar are model with high storage ?**\n",
        "\n"
      ],
      "metadata": {
        "id": "TFgKx6CKYHLX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Find models with high storage (assuming 'Memory' represents storage size)\n",
        "high_storage_models = data.sort_values(by='Memory', ascending=False).head(5)\n",
        "\n",
        "print(\"Models with High Storage:\")\n",
        "print(high_storage_models[['Model', 'Memory']])\n",
        "\n",
        "# Visualize models with high storage\n",
        "fig = px.bar(high_storage_models, x='Model', y='Memory',\n",
        "             labels={'Model': 'Model', 'Memory': 'Memory (GB)'},\n",
        "             title='Models with High Storage',\n",
        "             template='plotly_dark')\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "4WaIlKUuzouw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**visualize the relationship between 'RAM' and 'Memory' of mobile phones, and use 'Price' to determine the color of the points**."
      ],
      "metadata": {
        "id": "olCUQuWCPUzo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a scatter plot with color mapping based on 'Price'\n",
        "fig = px.scatter(data_frame=data, x='RAM', y='Memory', color='Price',\n",
        "                 labels={'RAM': 'RAM (GB)', 'Memory': 'Memory (GB)', 'Price': 'Price ($)'},\n",
        "                 title='Scatter Plot: RAM vs Memory (Color by Price)',\n",
        "                 template='plotly_dark')\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "iE0LIhQWz9Ut"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Which models offer the best value for money based on storage capacity and price?**"
      ],
      "metadata": {
        "id": "j60tEtOJ3BxG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the price per GB\n",
        "data['Price_per_GB'] = data['Price'] / data['Memory']\n",
        "\n",
        "# Sort the models by price per GB in ascending order (lower price per GB means better value for money)\n",
        "best_value_models = data.sort_values(by='Price_per_GB')\n",
        "\n",
        "# Display the top models offering the best value for money\n",
        "best_value_models[['Model', 'Memory', 'Price', 'Price_per_GB']].T"
      ],
      "metadata": {
        "id": "m1uJyQjgFjc9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize using Plotly Express\n",
        "fig = px.bar(best_value_models,\n",
        "             x='Model',\n",
        "             y='Price_per_GB',\n",
        "             hover_data=['Memory', 'Price'],\n",
        "             title='Best Value for Money Models (Price per GB)',\n",
        "             labels={'Price_per_GB': 'Price per GB'},\n",
        "             height=600)\n",
        "\n",
        "# Update layout for better visualization\n",
        "fig.update_layout(xaxis_title='Model', yaxis_title='Price per GB', xaxis_tickangle=-45)\n",
        "\n",
        "# Show the plot\n",
        "fig.show()\n"
      ],
      "metadata": {
        "id": "ChUcnXmSGFMf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['Price'].isnull().sum()"
      ],
      "metadata": {
        "id": "kiBPbe4n8ri6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Bar Chart: Average Battery Capacity by Processor**\n",
        "**What is the average battery capacity for each processor type?**"
      ],
      "metadata": {
        "id": "mhG9PrD1N4Zn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Group by processor type and calculate the average battery capacity\n",
        "avg_battery_by_processor = data.groupby('Processor_')['Battery_'].mean().reset_index()\n",
        "\n",
        "# Rename columns for clarity\n",
        "avg_battery_by_processor.columns = ['Processor', 'Average_Battery_Capacity']"
      ],
      "metadata": {
        "id": "U-lXGMG7Gg2y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "avg_battery_by_processor"
      ],
      "metadata": {
        "id": "GW7WzwkoWFWN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Heatmap: Correlation Between Features**\n",
        "**What are the correlations between different features in the dataset?**"
      ],
      "metadata": {
        "id": "SwFHjpkZPF6S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_cols.corr()"
      ],
      "metadata": {
        "id": "mnwjuevNsDUc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The correlation matrix shows:**\n",
        "\n",
        "- Most correlations between these features are weak, except for the strong positive relationships between Memory and RAM (0.625), and Battery and Mobile Height (0.696). This indicates that while some features like memory and RAM, and battery capacity and mobile height tend to increase together, most other features do not show strong linear relationships."
      ],
      "metadata": {
        "id": "-5EVXctOsaii"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the correlation matrix\n",
        "correlation_matrix=num_cols.corr()\n",
        "correlation_matrix\n",
        "# Create a heatmap for the num cols\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(num_col.corr(), annot=True, cmap='coolwarm', fmt='.2f')\n",
        "plt.title('Correlation Heatmap')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "LYGf2LPsPDl3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Histogram: Distribution of Mobile Heights**\n",
        "**What is the distribution of mobile heights?**"
      ],
      "metadata": {
        "id": "ymX5TpusPQgl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create histogram\n",
        "fig = px.histogram(data, x='Mobile Height',\n",
        "                   title='Distribution of Mobile Heights',\n",
        "                   labels={'Mobile Height': 'Mobile Height (mm)'},\n",
        "                   template='plotly_dark')\n",
        "\n",
        "# Show the plot\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "itRGe-p_Vd82"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Preprocessing**"
      ],
      "metadata": {
        "id": "ZPlge03MqzzX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_data.head()"
      ],
      "metadata": {
        "id": "O0LLFXTArq92"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_data.shape"
      ],
      "metadata": {
        "id": "NoDpLSSVfH39"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_data.isnull().sum()"
      ],
      "metadata": {
        "id": "EYeyymWAwMJa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Encode Categorical Features**"
      ],
      "metadata": {
        "id": "57ik2_-0sz-y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Label Encoding:**\n",
        "\n",
        "**Convert categorical variables into numerical labels. This is useful for algorithms that can handle numerical inputs but not categorical inputs.**"
      ],
      "metadata": {
        "id": "TgW4wAWdH2Hj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cat=cleaned_data.select_dtypes(include=['object'])"
      ],
      "metadata": {
        "id": "HLRkN9_bhJY8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cat"
      ],
      "metadata": {
        "id": "sJBcZi2_hSZU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# Dictionary to store the encoded values\n",
        "encoded_columns = {}\n",
        "\n",
        "# Encode categorical columns\n",
        "for column in cat:\n",
        "# Fit and transform the column\n",
        "encoded_columns[column] = label_encoder.fit_transform(cleaned_data[column])\n",
        "\n",
        "# Create a DataFrame of encoded values\n",
        "encoded_data = pd.DataFrame(encoded_columns)\n",
        "\n",
        "# Concatenate the encoded DataFrame with the cleaned_data DataFrame\n",
        "combined_data = pd.concat([cleaned_data.drop(columns=cat), encoded_data], axis=1)\n",
        "\n",
        "# Display the combined DataFrame\n",
        "print(\"\\nCombined DataFrame:\")\n",
        "combined_data"
      ],
      "metadata": {
        "id": "6j4hWnY2bz7O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_data"
      ],
      "metadata": {
        "id": "yRRtDA80mm4O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_encoder"
      ],
      "metadata": {
        "id": "IJZdQ_rHI5F1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " cleaned_data[column]"
      ],
      "metadata": {
        "id": "fTBctOX0Ym2w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "xlRPKmaYX2UR"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "X5FWhDE2WuYW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_data1"
      ],
      "metadata": {
        "id": "7fev52rYXY5Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **one-hot encoding**"
      ],
      "metadata": {
        "id": "ik_ItDoTIl07"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2Rf9dRWM33W"
      },
      "source": [
        "**Convert categorical variables (e.g., model, colour) into a suitable numerical format, such as one-hot encoding.**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sdjZW5OVKEUi"
      },
      "outputs": [],
      "source": [
        "# Apply one-hot encoding to categorical columns\n",
        "data_encoded = pd.get_dummies(data, columns=cf)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4NjzATYtLFQJ"
      },
      "outputs": [],
      "source": [
        "data_encoded"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Concatenate data1 and data2 along columns (axis=1)\n",
        "data_new = pd.concat([cleaned_data, encoded_data], axis=1)"
      ],
      "metadata": {
        "id": "a-WUz34UPfKj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_new"
      ],
      "metadata": {
        "id": "VIHQj3p3Q4YR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_new.columns"
      ],
      "metadata": {
        "id": "H6qdB4uCRAAg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assume 'prize' is the target variable\n",
        "X = cleaned_data.drop('Price', axis=1)\n",
        "y = cleaned_data['Price']\n"
      ],
      "metadata": {
        "id": "RWSNU7HAsb6p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Splitting data into training and test data\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.30,random_state=42)\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "id": "_PVk5gwEN8j-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Feature Scaling**\n",
        "- **Normalize/Standardize Numerical Features**"
      ],
      "metadata": {
        "id": "ueDVAXT4r9Lo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)"
      ],
      "metadata": {
        "id": "wswcD9DMsWXZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
      ],
      "metadata": {
        "id": "_yRk_1Eetjgo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "azoan_XxUjEZ"
      },
      "source": [
        "# **Feature Extraction**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OEboLA_9lQHM"
      },
      "source": [
        "# **1. Missing Value Ratio**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gJZIRDEa5qu0"
      },
      "outputs": [],
      "source": [
        "# Calculate the percentage of missing values for each feature\n",
        "missing_ratio = data.isnull().mean()\n",
        "\n",
        "# Display the missing value ratio\n",
        "print(\"Missing Value Ratio:\\n\", missing_ratio)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5_fVNMuLlrkL"
      },
      "source": [
        "**Remove Features with High Missing Value Ratio.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5jrvyO2alzF5"
      },
      "outputs": [],
      "source": [
        "# Set a threshold for missing values (e.g., 30%)\n",
        "threshold = 0.30\n",
        "\n",
        "# Select features that have a missing value ratio below the threshold\n",
        "features_to_keep = missing_ratio[missing_ratio < threshold].index\n",
        "\n",
        "# Create a new dataframe with selected features\n",
        "data_reduced = data[features_to_keep]\n",
        "\n",
        "# Display the reduced dataframe\n",
        "data_reduced"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_cols"
      ],
      "metadata": {
        "id": "gNejPW51I6t5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Standardize the numeric features (mean=0 and variance=1)\n",
        "scaler = StandardScaler()\n",
        "# Assuming 'num_cols' contains the names of numeric columns\n",
        "data[num_cols.columns] = scaler.fit_transform(data[num_cols.columns])\n"
      ],
      "metadata": {
        "id": "h1E1Yar6ouZK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[num_cols.columns]"
      ],
      "metadata": {
        "id": "tAbnM_TlJMBR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Univarient Feature Selection**"
      ],
      "metadata": {
        "id": "ltUMjxsATRXR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data['Price']"
      ],
      "metadata": {
        "id": "cGzHoYkd2sBF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import chi2\n",
        "from sklearn.impute import SimpleImputer\n"
      ],
      "metadata": {
        "id": "lZMePmg4Ukuy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.shape"
      ],
      "metadata": {
        "id": "qjaYYYXPWnMm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cat_col.columns"
      ],
      "metadata": {
        "id": "UtLwcK1YcioU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.isnull().sum()"
      ],
      "metadata": {
        "id": "nySZWjoUJoIz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a DataFrame to hold feature scores\n",
        "dfscores = pd.DataFrame(ordered_feature.scores_, columns=[\"Score\"])"
      ],
      "metadata": {
        "id": "YDa5k8hPwmdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a DataFrame to hold feature names\n",
        "dfcolumns = pd.DataFrame(X_encoded.columns, columns=[\"Features\"])"
      ],
      "metadata": {
        "id": "YcFbs1d5wpSq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Concatenate DataFrames to create a ranked feature list\n",
        "features_rank = pd.concat([dfcolumns, dfscores], axis=1)"
      ],
      "metadata": {
        "id": "_-BI6Nhnwtz6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Rename columns for clarity\n",
        "features_rank.columns = ['Features', 'Score']"
      ],
      "metadata": {
        "id": "PDShLJIwwwQx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the ranked features\n",
        "features_rank"
      ],
      "metadata": {
        "id": "VQy-jqiUwzNg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chi2_selector = SelectKBest(chi2, k=10)\n",
        "X_kbest = chi2_selector.fit_transform(X, y)\n",
        "chi2_scores = pd.DataFrame({'Feature': preprocessor.get_feature_names_out(), 'Chi2 Score': chi2_selector.scores_})\n",
        "chi2_scores = chi2_scores.sort_values(by='Chi2 Score', ascending=False)\n",
        "print(\"Chi-square Test:\")\n",
        "print(chi2_scores)"
      ],
      "metadata": {
        "id": "00IBoboYJ6VC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature Importance\n",
        "This technique gives you a score for each feature of your data,the higher the score mor relevant it is"
      ],
      "metadata": {
        "id": "Qx2qL_epgCgt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Filter Methods**\n",
        "- Filter methods evaluate the intrinsic properties of the features based on univariate statistics and do not involve any machine learning model. These methods are fast and computationally efficient, making them suitable for high-dimensional data."
      ],
      "metadata": {
        "id": "IkTmLQZRlXsM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import mutual_info_classif\n",
        "\n",
        "# Assuming X and y are your features and target variable\n",
        "information_gain = mutual_info_classif(X_imputed, y)"
      ],
      "metadata": {
        "id": "aVOPZ_oKlWY9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "information_gain"
      ],
      "metadata": {
        "id": "NqK2Eab0l7mH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Fishers Score:**\n",
        "\n",
        "Ranks variables based on their Fisher score, which measures the separation between classes."
      ],
      "metadata": {
        "id": "dYVHIocrmEiO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install skfeature"
      ],
      "metadata": {
        "id": "4qc6sS0NmxI7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def fisher_score(X, y):\n",
        "    classes = np.unique(y)\n",
        "    fisher_scores = []\n",
        "    for feature in X.T:\n",
        "        numerator = 0\n",
        "        denominator = 0\n",
        "        overall_mean = np.mean(feature)\n",
        "        for c in classes:\n",
        "            class_feature = feature[y == c]\n",
        "            class_mean = np.mean(class_feature)\n",
        "            class_variance = np.var(class_feature)\n",
        "            numerator += len(class_feature) * (class_mean - overall_mean) ** 2\n",
        "            denominator += len(class_feature) * class_variance\n",
        "        fisher_scores.append(numerator / denominator)\n",
        "    return np.array(fisher_scores)\n",
        "\n",
        "fisher_scores = fisher_score(X.values, y.values)\n",
        "fisher_score_df = pd.DataFrame({'Feature': X.columns, 'Fisher Score': fisher_scores})\n",
        "fisher_score_df = fisher_score_df.sort_values(by='Fisher Score', ascending=False)\n",
        "print(fisher_score_df)"
      ],
      "metadata": {
        "id": "5mbG1xexl-1g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Correlation Coefficient:**\n",
        "\n",
        "Measures the linear relationship between features and the target.\n",
        "High correlation with the target but low correlation among features is desired."
      ],
      "metadata": {
        "id": "ZYn6dBolmhRM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Feature Importance**\n",
        "- This technique gives you a score for each feature of your data,the higher the score mor relevant it is"
      ],
      "metadata": {
        "id": "7vIddCxAg-rt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Assuming 'X' is your DataFrame with categorical features\n",
        "label_encoders = {}\n",
        "imputer = SimpleImputer(strategy='most_frequent')  # Create imputer once\n",
        "X_imputed = imputer.fit_transform(X)  # Impute missing values for the entire DataFrame\n",
        "\n",
        "for i, col in enumerate(X.columns):\n",
        "    if X[col].dtype == 'object':\n",
        "        le = LabelEncoder()\n",
        "        X_imputed[:, i] = le.fit_transform(X_imputed[:, i])  # Encode the imputed column\n",
        "        label_encoders[col] = le  # Store the encoder for later use\n",
        "\n",
        "X = pd.DataFrame(X_imputed, columns=X.columns)  # Convert imputed array back to DataFrame\n",
        "\n",
        "model = ExtraTreesClassifier()\n",
        "model.fit(X, y)  # Now fit the model with the imputed and encoded DataFrame\n"
      ],
      "metadata": {
        "id": "ioS2ES-TmHWT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.feature_importances_)"
      ],
      "metadata": {
        "id": "BQnaeQ0emL8u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ranked_features=pd.Series(model.feature_importances_,index=X.columns)\n",
        "ranked_features.nlargest(10).plot(kind='barh')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qOBv6HtcmQ_e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_encoded.corr()"
      ],
      "metadata": {
        "id": "_yoBvl7DmX5V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "corr=num_cols.iloc[:,:-1].corr()\n",
        "top_features=corr.index\n",
        "plt.figure(figsize=(20,20))\n",
        "sns.heatmap(num_cols[top_features].corr(),annot=True)"
      ],
      "metadata": {
        "id": "O9CSxFpImoCB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " **Remove The correlated**"
      ],
      "metadata": {
        "id": "VMWYQy-HnQwB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "threshold=0.8"
      ],
      "metadata": {
        "id": "5OYPfIENnpt-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# find and remove correlated features\n",
        "def correlation(dataset, threshold):\n",
        "    col_corr = set()  # Set of all the names of correlated columns\n",
        "    corr_matrix = dataset.corr()\n",
        "    for i in range(len(corr_matrix.columns)):\n",
        "        for j in range(i):\n",
        "            if abs(corr_matrix.iloc[i, j]) > threshold: # we are interested in absolute coeff value\n",
        "                colname = corr_matrix.columns[i]  # getting the name of column\n",
        "                col_corr.add(colname)\n",
        "    return col_corr"
      ],
      "metadata": {
        "id": "VznnrCBmnUbr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correlation(num_cols.iloc[:,:-1],threshold)"
      ],
      "metadata": {
        "id": "2axtXNX3nfyv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Information Gain**"
      ],
      "metadata": {
        "id": "9jCCbiT5n4IW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import mutual_info_classif"
      ],
      "metadata": {
        "id": "0QX0A3k9n8lr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mutual_info=mutual_info_classif(X,y)"
      ],
      "metadata": {
        "id": "V71sXBNQoDj8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mutual_data=pd.Series(mutual_info,index=X.columns)\n",
        "mutual_data.sort_values(ascending=False)"
      ],
      "metadata": {
        "id": "3Pw4yRKFoGw1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SelectKBest with f_regression**"
      ],
      "metadata": {
        "id": "dbJ8g1Z8aIGf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import SelectKBest, f_regression\n",
        "from sklearn.impute import SimpleImputer\n",
        "#Convert 'Price' to numeric\n",
        "data['Price'] = pd.to_numeric(data['Price'], errors='coerce')\n",
        "\n",
        "#Extract numerical features excluding 'Price'\n",
        "numerical_features = data.select_dtypes(include=[np.number]).drop(columns=['Price'])\n",
        "\n",
        "# Impute missing values in numerical features using the mean strategy\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "numerical_features_imputed = imputer.fit_transform(numerical_features)\n",
        "\n",
        "# Example: Impute missing values in 'Price' column (target variable)\n",
        "imputer_price = SimpleImputer(strategy='mean')\n",
        "price_imputed = imputer_price.fit_transform(data[['Price']]).ravel()\n",
        "\n",
        "# Example: Perform SelectKBest feature selection using f_regression\n",
        "selector = SelectKBest(score_func=f_regression, k='all')\n",
        "selector.fit(numerical_features_imputed, price_imputed)\n",
        "\n",
        "# Get scores and feature names\n",
        "feature_scores = pd.DataFrame({'Feature': numerical_features.columns, 'Score': selector.scores_})\n",
        "feature_scores = feature_scores.sort_values(by='Score', ascending=False)\n",
        "\n",
        "\n",
        "\n",
        "#Print top features\n",
        "top_features = feature_scores['Feature'].tolist()[:5]\n",
        "top_features"
      ],
      "metadata": {
        "id": "SF1VoJ3daHRx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cf_khItvdAO0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Dimentionality Reduction**"
      ],
      "metadata": {
        "id": "0wL0PgI2dBNg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **t-Distributed Stochastic Neighbor Embedding (t-SNE)**"
      ],
      "metadata": {
        "id": "viPMiKfBc-X1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.manifold import TSNE\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer # Import SimpleImputer\n",
        "\n",
        "# Assuming 'data' is your DataFrame containing mobile phone data\n",
        "# Extract numerical features excluding 'Price'\n",
        "numerical_features = data.select_dtypes(include=[np.number]).drop(columns=['Price'])\n",
        "\n",
        "# Impute missing values using the mean strategy (or any other suitable strategy)\n",
        "imputer = SimpleImputer(strategy='mean') # Create an imputer instance\n",
        "numerical_features_imputed = imputer.fit_transform(numerical_features) # Impute NaNs\n",
        "\n",
        "# Standardize the features (mean=0 and variance=1)\n",
        "scaler = StandardScaler()\n",
        "numerical_features_scaled = scaler.fit_transform(numerical_features_imputed) # Scale imputed data\n",
        "\n",
        "# Apply t-SNE\n",
        "tsne = TSNE(n_components=2, random_state=0)\n",
        "tsne_components = tsne.fit_transform(numerical_features_scaled)\n",
        "\n",
        "# Create a DataFrame for the t-SNE components\n",
        "tsne_df = pd.DataFrame(data=tsne_components, columns=['Component 1', 'Component 2'])\n",
        "\n",
        "# Plotting t-SNE results\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(tsne_df['Component 1'], tsne_df['Component 2'])\n",
        "plt.title('t-SNE Visualization')\n",
        "plt.xlabel('Component 1')\n",
        "plt.ylabel('Component 2')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rVVKgxDadJga"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}